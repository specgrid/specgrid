import os
import time
from scipy import stats
import tempfile
from collections import OrderedDict
from logging import getLogger
import pandas as pd
import shutil

logger = getLogger(__name__)

import json

import numpy as np

from specgrid.fitting import BaseFitResult

try:
    import pymultinest
except ImportError:
    multinest_available = False
    raise
else:
    multinest_available = True

class MultinestResult():


    @classmethod
    def from_multinest_basename(cls, basename, parameter_names):
        """
        Reading a MultiNest result from a basename

        Parameters
        ----------

        basename: str
            basename (path + prefix) for a multinest run

        Returns
            : ~MultinestResult
        """

        posterior_data = cls.read_posterior_data(basename, parameter_names)

        return cls(posterior_data)

    @classmethod
    def from_hdf5(cls, h5_fname, key):
        """
        Reading a Multinest result from its generated HDF5 file

        Parameters
        ----------

        h5_fname: ~str
            HDF5 filename

        key: ~str
            group identifier in the store
        """

        posterior_data = pd.read_hdf(h5_fname, key)

        return cls(posterior_data)


    @staticmethod
    def read_posterior_data(basename, parameter_names):
        """
        Reading the posterior data into a pandas dataframe

        """
        posterior_data = pd.read_csv('{0}_.txt'.format(basename),
                           delim_whitespace=True,
                           names=['posterior', 'x'] + parameter_names)
        posterior_data.index = np.arange(len(posterior_data))
        return posterior_data

    def __init__(self, posterior_data):
        self.posterior_data = posterior_data
        self.parameter_names = [col_name for col_name in posterior_data.columns
                                if col_name not in ['x', 'posterior']]

    def calculate_sigmas(self, sigma):
        sigmas = OrderedDict()
        for parameter_name in self.parameter_names:
            posterior_data = self.posterior_data.sort(parameter_name)
            parameter_values, posterior_values = (posterior_data[parameter_name],
                                                  posterior_data['posterior'])
            posterior_cumsum = posterior_values.cumsum()

            norm_distr = stats.norm(loc=0.0, scale=1.)

            sigma_low = np.interp(norm_distr.cdf(-sigma), posterior_cumsum,
                                  parameter_values)

            sigma_high = np.interp(norm_distr.cdf(sigma), posterior_cumsum,
                                  parameter_values)


            sigmas[parameter_name] = (sigma_low, sigma_high)

        return sigmas

    @property
    def mean(self):
        if not hasattr(self, '_mean'):
            _mean = OrderedDict([(param_name,
                                  np.average(self.posterior_data[param_name],
                                             weights=
                                             self.posterior_data['posterior']))
                                 for param_name in self.parameter_names])
            self._mean = _mean

        return self._mean








class BaseMultinestFitter(object):
    """
    Use multinest to fit a spectrum using a grid of models generated by specgrid.

    Parameters
    ----------


    likelihood: ~Likelihood object, optional
        By default uses the Likelihood object which uses the chi-square for the
        likelihood of observing the data given the model param_names

    run_dir:

    """


    def __init__(self, likelihood, priors, run_dir=None, prefix='specgrid_multinest'):

        self.run_dir = run_dir
        self.prefix = prefix
        self.likelihood = likelihood
        self.priors = priors




    @property
    def n_params(self):
        return len(self.likelihood.param_names)

    @property
    def basename_(self):
        return '{0}_'.format(self.basename)

    @property
    def posterior_data(self):
        if self._posterior_data is None:
            self._posterior_data = self.read_posterior_data()

        return self._posterior_data

    def prepare_fit_directory(self, run_dir, prefix):
        if not os.path.exists(run_dir):
            os.mkdir(run_dir)

        # checking if previous chains already exist
        return os.path.join(run_dir, prefix)

    def run(self, clean_up=None, **kwargs):

        if clean_up is None:
            if self.run_dir is None:
                clean_up = True
            else:
                clean_up = False


        if self.run_dir is None:
            run_dir = tempfile.mkdtemp()
        else:
            run_dir = self.run_dir

        basename = self.prepare_fit_directory(run_dir, self.prefix)


        start_time = time.time()

        logger.info('Starting fit in {0} with prefix {1}'.format(run_dir, self.prefix))
        pymultinest.run(self.likelihood, self.priors.prior_transform,
                        self.n_params,
                        outputfiles_basename='{0}_'.format(basename),
                        **kwargs)

        logger.info("Fit finished - took {0:.2f} s"
                    .format(time.time() - start_time))

        self.result = MultinestResult.from_multinest_basename(
            basename, self.likelihood.param_names)

        if clean_up == True:
            logger.info("Cleaning up - deleting {0}".format(run_dir))
            shutil.rmtree(run_dir)

        return self.result





    def __repr__(self):
        return "{0}\n\n{1}".format(
            self.likelihood, self.priors)